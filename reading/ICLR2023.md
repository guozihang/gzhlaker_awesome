# ICLR 2023 Interested Papers

## Sign Language

1. Unsupervised Sign Language Translation and Generation [[Paper\]](https://openreview.net/attachment?id=eeaKRQIaYd&name=pdf)
2. Sign2GPT: Leveraging Large Language Models for Gloss-Free Sign Language Translation [[Paper\]](https://openreview.net/attachment?id=LqaEEs3UxU&name=pdf)
3. NaturalSigner: Diffusion Models are Natural Sign Language Generator [[Paper\]](https://openreview.net/attachment?id=4JjSJyT15z&name=pdf)
4. SignAvatars: A Large-scale 3D Sign Language Holistic Motion Dataset and Benchmark [[Paper\]](https://openreview.net/attachment?id=L2kbdthX5M&name=pdf)
5. SignKD: Multi-modal Hierarchical Knowledge Distillation for Continuous Sign Language Recognition [[Paper\]](https://openreview.net/attachment?id=YkRwadXWHd&name=pdf)

## Temporal Modeling

1. Revisiting the Temporal Modeling in Spatio-Temporal Predictive Learning under A Unified View [[Paper\]](https://openreview.net/attachment?id=8VHCeoBGxB&name=pdf)

## Action Recognition

1. FROSTER: Frozen CLIP is A Strong Teacher for Open-Vocabulary Action Recognition [[Paper\]](https://openreview.net/attachment?id=zYXFMeHRtO&name=pdf)
2. Unsupervised open-vocabulary action recognition with an autoregressive model [[Paper\]](https://openreview.net/attachment?id=IryGDUHxDE&name=pdf)
3. SpikePoint: An Efficient Point-based Spiking Neural Network for Event Cameras Action Recognition [[Paper\]](https://openreview.net/attachment?id=7etoNfU9uF&name=pdf)
4. Temporal Causal Mechanism Transfer for Few-shot Action Recognition [[Paper\]](https://openreview.net/attachment?id=ye3NrNrYOY&name=pdf)
5. FHA-Kitchens: A Novel Dataset for Fine-Grained Hand Action Recognition in Kitchen Scenes [[Paper\]](https://openreview.net/attachment?id=otoggKnn0A&name=pdf)
6. MaskCLR: Multi-Level Contrastive Learning for Robust Skeletal Action Recognition [[Paper\]](https://openreview.net/attachment?id=g0KxyULAun&name=pdf)
7. POET: Prompt Offset Tuning for Continual Few-Shot Action Recognition [[Paper\]](https://openreview.net/attachment?id=WGLu9Mv8mn&name=pdf)
8. Localized Linear Temporal Dynamics for Self-supervised Skeleton Action Recognition [[Paper\]](https://openreview.net/attachment?id=W7n78TNfKy&name=pdf)
9. EZ-CLIP: EFFICIENT ZERO-SHOT VIDEO ACTION RECOGNITION [[Paper\]](https://openreview.net/attachment?id=hWjPRRyiqm&name=pdf)

## Speech Recognition

1. AV-CPL: Continuous Pseudo-Labeling for Audio-Visual Speech Recognition [[Paper\]](https://openreview.net/attachment?id=k542OjwsQK&name=pdf)
2. SummaryMixing: A Linear-Complexity Alternative to Self-Attention for Speech Recognition and Understanding [[Paper\]](https://openreview.net/attachment?id=PoBB8n52oi&name=pdf)
3. Multilingual Visual Speech Recognition with a Single Model using Visual Speech Unit [[Paper\]](https://openreview.net/attachment?id=M8J0b9gNfG&name=pdf)
4. SELF-TAILORING PROMPTS FOR PARAMETER EFFICIENT TUNING SPEECH RECOGNITION [[Paper\]](https://openreview.net/attachment?id=rgjmqqP923&name=pdf)
5. Federated Learning with Differential Privacy for End-to-End Speech Recognition [[Paper\]](https://openreview.net/attachment?id=zI6fKENVL8&name=pdf)
6. SMILE: Audio-Visual Speech Recognition with Siamese Masked Interaction Learning [[Paper\]](https://openreview.net/attachment?id=74IIsh2kM6&name=pdf)
7. Large Language Models are Efficient Learners of Noise-Robust Speech Recognition [[Paper\]](https://openreview.net/attachment?id=ceATjGPTUD&name=pdf)
8. It's Never Too Late: Fusing Acoustic Information into Large Language Models for Automatic Speech Recognition [[Paper\]](https://openreview.net/attachment?id=QqjFHyQwtF&name=pdf)
9. Zipformer: A faster and better encoder for automatic speech recognition [[Paper\]](https://openreview.net/attachment?id=9WD9KwssyT&name=pdf)

## GPT

1. NExT-GPT: Any-to-Any Multimodal LLM [[Paper\]](https://openreview.net/attachment?id=0A5o6dCKeK&name=pdf)

## Multi Model

1. MMPareto: Innocent Uni-modal Assistance for Enhanced Multi-modal Learning [[Paper\]](https://openreview.net/attachment?id=JHD4Q4GbXa&name=pdf)
2. Quantifying and Enhancing Multi-modal Robustness with Modality Preference [[Paper\]](https://openreview.net/attachment?id=XyrB1Ay44j&name=pdf)

## Pre-train

1. FairVLM: Mitigating Bias In Pre-Trained Vision-Language Models [[Paper\]](https://openreview.net/attachment?id=HXoq9EqR9e&name=pdf)
2. UniBoost: Boost Zero-shot Vision-Language Tasks via Multitask Fine-tuning with Unsupervised Unimodal Pre-training [[Paper\]](https://openreview.net/attachment?id=RlcWvyf5rm&name=pdf)
3. Emergent Corpus Pretraining Benefits Vision Language Modeling [[Paper\]](https://openreview.net/attachment?id=vSkcS3qnZk&name=pdf)
4. Tag2Text: Guiding Vision-Language Model via Image Tagging [[Paper\]](https://openreview.net/attachment?id=x6u2BQ7xcq&name=pdf)
5. Revisiting the Role of Language Priors in Vision-Language Models [[Paper\]](https://openreview.net/attachment?id=WZ6NY4JfFX&name=pdf)
6. Enhancing Vision-Language Model with Unmasked Token Alignment at Scale [[Paper\]](https://openreview.net/attachment?id=DOerIFfUbs&name=pdf)
7. In-context Prompt Learning for Test-time Vision Recognition with Frozen Vision-Language Model [[Paper\]](https://openreview.net/attachment?id=Rc3RP9OoEJ&name=pdf)
8. Unsupervised Open-Set Task Adaptation Using a Vision-Language Foundation Model [[Paper\]](https://openreview.net/attachment?id=FRjflOWx2W&name=pdf)