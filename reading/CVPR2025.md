# CVPR2025 Interested Papers

## Context

- 【CVPR 2025】Adaptive Markup Language Generation for Contextually-Grounded Visual Document Understanding
  
- 【CVPR 2025】**ECVC: Exploiting Non-Local Correlations in Multiple Frames for Contextual Video Compression**
  
- 【CVPR 2025】Video-ColBERT: Contextualized Late Interaction for Text-to-Video Retrieval
- 【CVPR 2025】**Contextual AD Narration with Interleaved Multimodal Sequence**


## Alignment

- 【CVPR 2025】**Task Preference Optimization: Improving Multimodal Large Language Models Performance with Vision Task Alignment**
- 【CVPR 2025】**Towards Improved Text-Aligned Codebook Learning: Multi-Hierarchical Codebook-Text Alignment with Long Text**
- 【CVPR 2025】**AlignMamba: Enhancing Multimodal Mamba with Local and Global Cross-modal Alignment**
- 【CVPR 2025】**Robust Audio-Visual Segmentation via Audio-Guided Visual Convergent Alignment**
- 【CVPR 2025】**Cross-modal Causal Relation Alignment for Video Question Grounding**
- 【CVPR 2025】Harnessing Frozen Unimodal Encoders for Flexible Multimodal Alignment
- 【CVPR 2025】**Assessing and Learning Alignment of Unimodal Vision and Language Models**
- 【CVPR 2025】Temporal Alignment-Free Video Matching for Few-shot Action Recognition
- 【CVPR 2025】Rethinking Noisy Video-Text Retrieval via Relation-aware Alignment
- 【CVPR 2025】Can Text-to-Video Generation help Video-Language Alignment?
- 【CVPR 2025】**Video-Panda: Parameter-efficient Alignment for Encoder-free Video-Language Models**

## Weakly Supervised

- 【CVPR 2025】**STPro: Spatial and Temporal Progressive Learning for Weakly Supervised Spatio-Temporal Grounding**

## Domain

- 【CVPR 2025】**TIDE: Training Locally Interpretable Domain Generalization Models Enables Test-time Correction**

## Pesudo

- 【CVPR 2025】Federated Semi-Supervised Learning via Pseudo-Correction utilizing Confidence Discrepancy
- 【CVPR 2025】Dynamic Pseudo Labeling via Gradient Cutting for High-Low Entropy Exploration
- 【CVPR 2025】ROLL: Robust Noisy Pseudo-label Learning for Multi-View Clustering with Noisy Correspondence

## Attention

- 【CVPR 2025】**Efficient Event-Based Object Detection: A Hybrid Neural Network with Spatial and Temporal Attention**
- 【CVPR 2025】**Omni-scale Context Modeling with State Space Models and Local Attention for Semantic Segmentation**
- 【CVPR 2025】**Spiking Transformer with Spatial-Temporal Attention**
- 【CVPR 2025】**SEAL: Semantic Attention Learning for Long Video Representation**
- 【CVPR 2025】FIFA: Fine-grained Inter-frame Attention for Driver's Video Gaze Estimation
- 【CVPR 2025】**Breaking the Low-Rank Dilemma of Linear Attention**
- 【CVPR 2025】**Text Embedding is Not All You Need: Attention Control for Text-to-Image Semantic Alignment with Text Self-Attention Maps**
- 【CVPR 2025】**Split Adaptation for Pre-trained Vision Transformers**
- 【CVPR 2025】**Mr. DETR: Multi-Route Training for Detection Transformers with Instructive Self-Attention**

## Transformer

- 【CVPR 2025】Structured Artifact Removal with Scale-Adaptive Deformable Transformer
- 【CVPR 2025】Text Augmented Correlation Transformer For Few-shot Classification & Segmentation
- 【CVPR 2025】Transformers without Normalization



## Mamba

- MambaVision: A Hybrid Mamba-Transformer Vision Backbone
- MobileMamba: Lightweight Multi-Receptive Visual Mamba Network

## MLLM

- LSceneLLM: Enhancing Large 3D Scene Understanding Using Adaptive Visual Preferences
- DynRefer: Delving into Region-level Multimodal Tasks via Dynamic Resolution
- Retrieval-Augmented Personalization for Multimodal Large Language Models

## Vision Language 

- NLPrompt: Noise-Label Prompt Learning for Vision-Language Models

## Video Understanding

- Temporal Grounding Videos like Flipping Manga