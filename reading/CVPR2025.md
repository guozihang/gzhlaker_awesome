# CVPR2025 Interested Papers

## Context

- Adaptive Markup Language Generation for Contextually-Grounded Visual Document Understanding
  
- **ECVC: Exploiting Non-Local Correlations in Multiple Frames for Contextual Video Compression**
  
- Video-ColBERT: Contextualized Late Interaction for Text-to-Video Retrieval
- **Contextual AD Narration with Interleaved Multimodal Sequence**


## Alignment

- **Task Preference Optimization: Improving Multimodal Large Language Models Performance with Vision Task Alignment**
- **Towards Improved Text-Aligned Codebook Learning: Multi-Hierarchical Codebook-Text Alignment with Long Text**
- **AlignMamba: Enhancing Multimodal Mamba with Local and Global Cross-modal Alignment**
- **Robust Audio-Visual Segmentation via Audio-Guided Visual Convergent Alignment**
- **Cross-modal Causal Relation Alignment for Video Question Grounding**
- Harnessing Frozen Unimodal Encoders for Flexible Multimodal Alignment
- **Assessing and Learning Alignment of Unimodal Vision and Language Models**
- Temporal Alignment-Free Video Matching for Few-shot Action Recognition
- Rethinking Noisy Video-Text Retrieval via Relation-aware Alignment
- Can Text-to-Video Generation help Video-Language Alignment?
- **Video-Panda: Parameter-efficient Alignment for Encoder-free Video-Language Models**
- GOAL: Global-local Object Alignment Learning
- Enhanced OoD Detection through Cross-Modal Alignment of Multi-Modal Representations
- Semantic and Sequential Alignment for Referring Video Object Segmentation
- SmartCLIP: Modular Vision-language Alignment with Identification Guarantees
- DiscoVLA: Discrepancy Reduction in Vision, Language, and Alignment for Parameter-Efficient Video-Text Retrieval
- Hybrid Reciprocal Transformer with Triplet Feature Alignment for Scene Graph Generation
- DH-Set: Improving Vision-Language Alignment with Diverse and Hybrid Set-Embeddings Learning
- Advancing Fine-Grained Compositional Alignment in Video-Text Models
- Post-pre-training for Modality Alignment in Vision-Language Foundation Models
- Chat-based Person Retrieval via Dialogue-Refined Cross-Modal Alignment
- Q-Eval-100K: Evaluating Visual Quality and Alignment Level for Text-to-Vision Content
- Alignment, Mining and Fusion: Representation Alignment with Hard Negative Mining and Selective Knowledge Fusion for Medical Visual Question Answering
- FineLIP: Extending CLIPâ€™s Reach via Fine-Grained Alignment with Longer Text Inputs
- Incorporating Dense Knowledge Alignment into Unified Multimodal Representation Models
- Text Embedding is Not All You Need: Attention Control for Text-to-Image Semantic Alignment with Text Self-Attention Maps
- Temporal Alignment-Free Video Matching for Few-shot Action Recognition

## Weakly Supervised

- **STPro: Spatial and Temporal Progressive Learning for Weakly Supervised Spatio-Temporal Grounding**

## Domain

- **TIDE: Training Locally Interpretable Domain Generalization Models Enables Test-time Correction**

## Pesudo

- Federated Semi-Supervised Learning via Pseudo-Correction utilizing Confidence Discrepancy
- Dynamic Pseudo Labeling via Gradient Cutting for High-Low Entropy Exploration
- ROLL: Robust Noisy Pseudo-label Learning for Multi-View Clustering with Noisy Correspondence

## Attention

- **Efficient Event-Based Object Detection: A Hybrid Neural Network with Spatial and Temporal Attention**
- **Omni-scale Context Modeling with State Space Models and Local Attention for Semantic Segmentation**
- **Spiking Transformer with Spatial-Temporal Attention**
- **SEAL: Semantic Attention Learning for Long Video Representation**
- FIFA: Fine-grained Inter-frame Attention for Driver's Video Gaze Estimation
- **Breaking the Low-Rank Dilemma of Linear Attention**
- **Text Embedding is Not All You Need: Attention Control for Text-to-Image Semantic Alignment with Text Self-Attention Maps**
- **Split Adaptation for Pre-trained Vision Transformers**
- **Mr. DETR: Multi-Route Training for Detection Transformers with Instructive Self-Attention**

## Transformer

- Structured Artifact Removal with Scale-Adaptive Deformable Transformer
- Text Augmented Correlation Transformer For Few-shot Classification & Segmentation
- Transformers without Normalization



## Mamba

- MambaVision: A Hybrid Mamba-Transformer Vision Backbone
- MobileMamba: Lightweight Multi-Receptive Visual Mamba Network

## MLLM

- LSceneLLM: Enhancing Large 3D Scene Understanding Using Adaptive Visual Preferences
- DynRefer: Delving into Region-level Multimodal Tasks via Dynamic Resolution
- Retrieval-Augmented Personalization for Multimodal Large Language Models

## Vision Language 

- NLPrompt: Noise-Label Prompt Learning for Vision-Language Models

## Video Understanding

- Temporal Grounding Videos like Flipping Manga