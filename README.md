## Sign Language

### Continous Sign Language Recognition

Conference

- 【ACMMM 2023】AdaBrowse: Adaptive Video Browser for Efficient Continuous Sign Language Recognition. [[Paper]](https://dl.acm.org/doi/10.1145/3581783.3611745) [![citation](https://img.shields.io/badge/dynamic/json?label=citation&query=citationCount&url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F94feda32ed1374a831d5ae5b0ec31bb247b1144e%3Ffields%3DcitationCount)](https://www.semanticscholar.org/paper/AdaBrowse%3A-Adaptive-Video-Browser-for-Efficient-Hu-Gao/94feda32ed1374a831d5ae5b0ec31bb247b1144e)
- 【ACMMM 2023】Towards Real-Time Sign Language Recognition and Translation on Edge Devices. [[Paper](https://dl.acm.org/doi/10.1145/3581783.3611820)] [![citation](https://img.shields.io/badge/dynamic/json?label=citation&query=citationCount&url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2Fdba462bcf68db62a4722c7f220f38461ff981f15%3Ffields%3DcitationCount)](https://www.semanticscholar.org/paper/Towards-Real-Time-Sign-Language-Recognition-and-on-Gan-Yin/dba462bcf68db62a4722c7f220f38461ff981f15)
- 【ICCV 2023】CoSign: Exploring Co-occurrence Signals in Skeleton-based Continuous Sign Language Recognition. [[Paper](https://openaccess.thecvf.com/content/ICCV2023/html/Jiao_CoSign_Exploring_Co-occurrence_Signals_in_Skeleton-based_Continuous_Sign_Language_Recognition_ICCV_2023_paper.html)] [![citation](https://img.shields.io/badge/dynamic/json?label=citation&query=citationCount&url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F522ef67f9c3316c42af569917fe054cd809891a9%3Ffields%3DcitationCount)](https://www.semanticscholar.org/paper/CoSign%3A-Exploring-Co-occurrence-Signals-in-Sign-Jiao-Min/522ef67f9c3316c42af569917fe054cd809891a9)
- 【ICCV 2023】Improving Continuous Sign Language Recognition with Cross-Lingual Signs. [[Paper](https://openaccess.thecvf.com/content/ICCV2023/html/Wei_Improving_Continuous_Sign_Language_Recognition_with_Cross-Lingual_Signs_ICCV_2023_paper.html)] [![citation](https://img.shields.io/badge/dynamic/json?label=citation&query=citationCount&url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F33a1ded05faa8ddb136fcec3d27551be6717010b%3Ffields%3DcitationCount)](https://www.semanticscholar.org/paper/Improving-Continuous-Sign-Language-Recognition-with-Wei-Chen/33a1ded05faa8ddb136fcec3d27551be6717010b)
- 【ICCV 2023】C2ST: Cross-modal Contextualized Sequence Transduction for Continuous Sign Language Recognition. [[Paper](https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_C2ST_Cross-Modal_Contextualized_Sequence_Transduction_for_Continuous_Sign_Language_Recognition_ICCV_2023_paper.html)] [![citation](https://img.shields.io/badge/dynamic/json?label=citation&query=citationCount&url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F7506bd96a8bf35beea6613ae7d087244fb34454f%3Ffields%3DcitationCount)](https://www.semanticscholar.org/paper/C2ST%3A-Cross-modal-Contextualized-Sequence-for-Sign-Zhang-Guo/7506bd96a8bf35beea6613ae7d087244fb34454f)
- 【EMNLP Findings 2023]】Handshape-Aware Sign Language Recognition: Extended Datasets and Exploration of Handshape-Inclusive Methods. [[paper\]](https://aclanthology.org/2023.findings-emnlp.198/) [![citation](https://img.shields.io/badge/dynamic/json?label=citation&query=citationCount&url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F3b417db486ef1a0442167907eb0cd8bb604d153e%3Ffields%3DcitationCount)](https://www.semanticscholar.org/paper/Handshape-Aware-Sign-Language-Recognition%3A-Extended-Zhang-Duh/3b417db486ef1a0442167907eb0cd8bb604d153e)
- 【AAAI 2023】Self-Emphasizing Network for Continuous Sign Language Recognition. [[Paper](https://ojs.aaai.org/index.php/AAAI/article/view/25164)] [[Code]](https://github.com/hulianyuyy/SEN_CSLR) [![citation](https://img.shields.io/badge/dynamic/json?label=citation&query=citationCount&url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F1f55d35e1d1a148898a756cb0380b22fa8878dcb%3Ffields%3DcitationCount)](https://www.semanticscholar.org/paper/Self-Emphasizing-Network-for-Continuous-Sign-Hu-Gao/1f55d35e1d1a148898a756cb0380b22fa8878dcb)
- 【CVPR 2023】CVT-SLR: Contrastive Visual-Textual Transformation for Sign Language Recognition with Variational Alignment. [[Paper](https://openaccess.thecvf.com/content/CVPR2023/html/Zheng_CVT-SLR_Contrastive_Visual-Textual_Transformation_for_Sign_Language_Recognition_With_Variational_CVPR_2023_paper.html)] [[Code](https://github.com/binbinjiang/CVT-SLR)] [![citation](https://img.shields.io/badge/dynamic/json?label=citation&query=citationCount&url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2Fff03fe2efa8e0283f06098e9f1ae41b76e66efec%3Ffields%3DcitationCount)](https://www.semanticscholar.org/paper/CVT-SLR%3A-Contrastive-Visual-Textual-Transformation-Zheng-Wang/ff03fe2efa8e0283f06098e9f1ae41b76e66efec)
- 【CVPR 2023】Continuous Sign Language Recognition with Correlation Network. [[Paper](https://openaccess.thecvf.com/content/CVPR2023/html/Hu_Continuous_Sign_Language_Recognition_With_Correlation_Network_CVPR_2023_paper.html)] [[Code](https://github.com/hulianyuyy/CorrNet)] [![citation](https://img.shields.io/badge/dynamic/json?label=citation&query=citationCount&url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2Fd9c38e7957c10252cc0e66b20c55d5be615db10d%3Ffields%3DcitationCount)](https://www.semanticscholar.org/paper/Continuous-Sign-Language-Recognition-with-Network-Hu-Gao/d9c38e7957c10252cc0e66b20c55d5be615db10d)
- 【CVPR 2023】Distilling Cross-Temporal Contexts for Continuous Sign Language Recognition. [[Paper](https://openaccess.thecvf.com/content/CVPR2023/html/Guo_Distilling_Cross-Temporal_Contexts_for_Continuous_Sign_Language_Recognition_CVPR_2023_paper.html)] [![citation](https://img.shields.io/badge/dynamic/json?label=citation&query=citationCount&url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2Fb8bc9c1b89e8b7a63cf97efdfb8e8f4954accf92%3Ffields%3DcitationCount)](https://www.semanticscholar.org/paper/Distilling-Cross-Temporal-Contexts-for-Continuous-Guo-Xue/b8bc9c1b89e8b7a63cf97efdfb8e8f4954accf92)
- 【ECCV 2024】 EvSign: Sign Language Recognition and Translation with Streaming Events. [[paper]](https://www.ecva.net/papers/eccv_2024/papers_ECCV/papers/00799.pdf) [![citation](https://img.shields.io/badge/dynamic/json?label=citation&query=citationCount&url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F5fadb52eeebcf45283a87972ffb28b56b22a8cb6%3Ffields%3DcitationCount)](https://www.semanticscholar.org/paper/EvSign%3A-Sign-Language-Recognition-and-Translation-Zhang-Yin/5fadb52eeebcf45283a87972ffb28b56b22a8cb6)
- 【EMNLP 2024】Towards Online Continuous Sign Language Recognition and Translation. [[paper\]](https://aclanthology.org/2024.emnlp-main.619/)] [![citation](https://img.shields.io/badge/dynamic/json?label=citation&query=citationCount&url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F8a515cec1559414759aa3c732fa5f4ceb8972267%3Ffields%3DcitationCount)](https://www.semanticscholar.org/paper/Towards-Online-Continuous-Sign-Language-Recognition-Zuo-Wei/8a515cec1559414759aa3c732fa5f4ceb8972267)
- 【AAAI 2024】KD-MSLRT: Lightweight Sign Language Recognition Model Based on Mediapipe and 3D to 1D Knowledge Distillation. [[Paper](https://arxiv.org/pdf/2501.02321)] [![citation](https://img.shields.io/badge/dynamic/json?label=citation&query=citationCount&url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F8f410c66930e736098e8938eb5e1ccd3b11b7599%3Ffields%3DcitationCount)](https://www.semanticscholar.org/paper/KD-MSLRT%3A-Lightweight-Sign-Language-Recognition-on-Li-Ren/8f410c66930e736098e8938eb5e1ccd3b11b7599)
- 【AAAI 2024】Cross-Sentence Gloss Consistency for Continuous Sign Language Recognition. [[Paper](https://ojs.aaai.org/index.php/AAAI/article/view/28265/28521)] [![citation](https://img.shields.io/badge/dynamic/json?label=citation&query=citationCount&url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2Fc8536a77bde76cd1bf621372407b0413585a5524%3Ffields%3DcitationCount)](https://www.semanticscholar.org/paper/Cross-Sentence-Gloss-Consistency-for-Continuous-Rao-Sun/c8536a77bde76cd1bf621372407b0413585a5524)
- 【AAAI 2024】TCNet: Continuous Sign Language Recognition from Trajectories and Correlated Regions. [[Paper](https://arxiv.org/pdf/2403.11818)] [![citation](https://img.shields.io/badge/dynamic/json?label=citation&query=citationCount&url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F866dec836ea1733952b7b99a0a57e290ff54a114%3Ffields%3DcitationCount)](https://www.semanticscholar.org/paper/TCNet%3A-Continuous-Sign-Language-Recognition-from-Lu-Salah/866dec836ea1733952b7b99a0a57e290ff54a114)
- 【CVPR 2024】SignGraph: A Sign Sequence is Worth Graphs of Nodes. [[Paper]](https://openaccess.thecvf.com/content/CVPR2024/papers/Gan_SignGraph_A_Sign_Sequence_is_Worth_Graphs_of_Nodes_CVPR_2024_paper.pdf) [[code]](https://github.com/gswycf/SignGraph/tree/main) [![citation](https://img.shields.io/badge/dynamic/json?label=citation&query=citationCount&url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F5d242b9dd28a64837ae6bfb389bc07b012a4309d%3Ffields%3DcitationCount)](https://www.semanticscholar.org/paper/SignGraph%3A-A-Sign-Sequence-is-Worth-Graphs-of-Nodes-Gan-Yin/5d242b9dd28a64837ae6bfb389bc07b012a4309d)
- 【IJCAI 2023】Contrastive Learning for Sign Language Recognition and Translation. [[Paper](https://www.ijcai.org/proceedings/2023/0085.pdf)] [![citation](https://img.shields.io/badge/dynamic/json?label=citation&query=citationCount&url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2Fb504e71ad831b0a16c5704bd66f20ccd6aff1353%3Ffields%3DcitationCount)](https://www.semanticscholar.org/paper/Contrastive-Learning-for-Sign-Language-Recognition-Gan-Yin/b504e71ad831b0a16c5704bd66f20ccd6aff1353)

Submittion

- 【ICLR 2024】SignKD: Multi-modal Hierarchical Knowledge Distillation for Continuous Sign Language Recognition. [[Paper](https://openreview.net/pdf?id=YkRwadXWHd)]

Journal

  - （TMM 2023）Prior-Aware Cross Modality Augmentation Learning for Continuous Sign Language Recognition. [[Paper](https://ieeexplore.ieee.org/document/10105511)] [![citation](https://img.shields.io/badge/dynamic/json?label=citation&query=citationCount&url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F39d8926d911033e2f9a4702c3f446f04fb887e97%3Ffields%3DcitationCount)](https://www.semanticscholar.org/paper/Prior-Aware-Cross-Modality-Augmentation-Learning-Hu-Pu/39d8926d911033e2f9a4702c3f446f04fb887e97)

  - #（TETCI 2024）Spatial Temporal Aggregation for Efficient Continuous Sign Language Recognition. [[Paper](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10488467)] [![citation](https://img.shields.io/badge/dynamic/json?label=citation&query=citationCount&url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F1d9614d37ca3d3060e291e1769c080ee6e52f0e6%3Ffields%3DcitationCount)](https://www.semanticscholar.org/paper/Spatial-Temporal-Aggregation-for-Efficient-Sign-Hu-Gao/1d9614d37ca3d3060e291e1769c080ee6e52f0e6)

  - （TIP 2024）Gloss Prior Guided Visual Feature Learning for Continuous Sign Language Recognition. [[Paper](https://ieeexplore.ieee.org/document/10542663)] [![citation](https://img.shields.io/badge/dynamic/json?label=citation&query=citationCount&url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2Fe52bc5b5d774619730a5aab9d2e6598cd962d158%3Ffields%3DcitationCount)](https://www.semanticscholar.org/paper/Gloss-Prior-Guided-Visual-Feature-Learning-for-Sign-Guo-Xue/e52bc5b5d774619730a5aab9d2e6598cd962d158)

  - （TCSVT 2023）Spatial-Temporal Enhanced Network for Continuous Sign Language Recognition. [[Paper](https://ieeexplore.ieee.org/document/10185608)] [![citation](https://img.shields.io/badge/dynamic/json?label=citation&query=citationCount&url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F5fadb52eeebcf45283a87972ffb28b56b22a8cb6%3Ffields%3DcitationCount)](https://www.semanticscholar.org/paper/EvSign%3A-Sign-Language-Recognition-and-Translation-Zhang-Yin/5fadb52eeebcf45283a87972ffb28b56b22a8cb6)

  - （TMM 2023）Collaborative Multilingual Continuous Sign Language Recognition: A Unified Framework. [[Paper](https://ieeexplore.ieee.org/document/9954921)] [![citation](https://img.shields.io/badge/dynamic/json?label=citation&query=citationCount&url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F03c1eda1173a3eae8a87a7889057a955114b758f%3Ffields%3DcitationCount)](https://www.semanticscholar.org/paper/Collaborative-Multilingual-Continuous-Sign-Language-Hu-Pu/03c1eda1173a3eae8a87a7889057a955114b758f)

  - （TMM 2024）A Sign Language Recognition Framework Based on Cross-Modal Complementary Information Fusion. [[Paper](https://ieeexplore.ieee.org/document/10472077)] [![citation](https://img.shields.io/badge/dynamic/json?label=citation&query=citationCount&url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F4556c5a7a71bd7c84b4227bd5754d4c2af44fafd%3Ffields%3DcitationCount)](https://www.semanticscholar.org/paper/A-Sign-Language-Recognition-Framework-Based-on-Zhang-Wang/4556c5a7a71bd7c84b4227bd5754d4c2af44fafd)

  - （PR 2024）Scalable Frame Resolution for Efficient Continuous Sign Language Recognition. [[Paper](https://www.sciencedirect.com/science/article/pii/S0031320323006015)] [![citation](https://img.shields.io/badge/dynamic/json?label=citation&query=citationCount&url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2Fc4c985700f4dc2b391d052e103fce3664c570a14%3Ffields%3DcitationCount)](https://www.semanticscholar.org/paper/Scalable-frame-resolution-for-efficient-continuous-Hu-Gao/c4c985700f4dc2b391d052e103fce3664c570a14)

  - （PR 2023）Multi-scale local-temporal similarity fusion for continuous sign language recognition. [[Paper](https://arxiv.org/pdf/2107.12762)] [![citation](https://img.shields.io/badge/dynamic/json?label=citation&query=citationCount&url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2Fa514cc9796034bcc01450ac968b2f576fa35c70f%3Ffields%3DcitationCount)](https://www.semanticscholar.org/paper/Multi-Scale-Local-Temporal-Similarity-Fusion-for-Xie-Cui/a514cc9796034bcc01450ac968b2f576fa35c70f)

  - （TPAMI 2025）MixSignGraph: A Sign Sequence is Worth Mixed Graphs of Nodes. [[Paper](https://arxiv.org/pdf/2504.12020)] [![citation](https://img.shields.io/badge/dynamic/json?label=citation&query=citationCount&url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F343b2ad9df6ef046d6a80de5acb38039b89d7e0d%3Ffields%3DcitationCount)](https://www.semanticscholar.org/paper/MixSignGraph%3A-A-Sign-Sequence-is-Worth-Mixed-Graphs-Gan-Yin/343b2ad9df6ef046d6a80de5acb38039b89d7e0d)

Preprint

  * 「Arxiv 2024.01.22」SignVTCL: Multi-Modal Continuous Sign Language Recognition Enhanced by Visual-Textual Contrastive Learning. [[Paper](https://arxiv.org/pdf/2401.11847)] [![citation](https://img.shields.io/badge/dynamic/json?label=citation&query=citationCount&url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2Fe03669834ea3e8c2d9bf3cc95c3089a390ad2e61%3Ffields%3DcitationCount)](https://www.semanticscholar.org/paper/SignVTCL%3A-Multi-Modal-Continuous-Sign-Language-by-Chen-Wang/e03669834ea3e8c2d9bf3cc95c3089a390ad2e61)
  * 「Arxiv 2024.02.29」Continuous Sign Language Recognition Based on Motor attention mechanism and frame-level Self-distillation. [[Paper](https://arxiv.org/pdf/2402.19118)]
  * 「Arxiv 2024.04.12」Improving Continuous Sign Language Recognition with Adapted Image Models [[Paper](https://arxiv.org/pdf/2404.08226)] [[Code](https://github.com/hulianyuyy/AdaptSign)] [![citation](https://img.shields.io/badge/dynamic/json?label=citation&query=citationCount&url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F2baa74ba055b1fc993ea19ea61df41ab5c8c2713%3Ffields%3DcitationCount)](https://www.semanticscholar.org/paper/Continuous-Sign-Language-Recognition-Based-on-Motor-Zhu-Li/2baa74ba055b1fc993ea19ea61df41ab5c8c2713)
  * 「Arxiv 2024.04.17」CorrNet+: Sign Language Recognition and Translation via Spatial-Temporal Correlation [[Paper](https://arxiv.org/pdf/2404.11111)] [[Code](https://github.com/hulianyuyy/CorrNet_Plus)] [![citation](https://img.shields.io/badge/dynamic/json?label=citation&query=citationCount&url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F9be7803e976227307b1bd0f3666901eae9fb05ca%3Ffields%3DcitationCount)](https://www.semanticscholar.org/paper/CorrNet%2B%3A-Sign-Language-Recognition-and-Translation-Hu-Feng/9be7803e976227307b1bd0f3666901eae9fb05ca)
  * 「Arxiv 2024.04.21」Stream State-tying for Sign Language Recognition. [[Paper](https://arxiv.org/pdf/2407.10975)] [![citation](https://img.shields.io/badge/dynamic/json?label=citation&query=citationCount&url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2Fb7431688f75b6e7f1c19862804980c660c021e5e%3Ffields%3DcitationCount)](https://www.semanticscholar.org/paper/Stream-State-tying-for-Sign-Language-Recognition-Ma-Gao/b7431688f75b6e7f1c19862804980c660c021e5e)
  * 「Arxiv 2024.05.02」A Hong Kong Sign Language Corpus Collected from Sign-interpreted TV News [[Paper](https://arxiv.org/pdf/2405.00980)] [![citation](https://img.shields.io/badge/dynamic/json?label=citation&query=citationCount&url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2Feabce17185aa25bdd86d675f8958d7cfabe3938b%3Ffields%3DcitationCount)](https://www.semanticscholar.org/paper/A-Hong-Kong-Sign-Language-Corpus-Collected-from-TV-Niu-Zuo/eabce17185aa25bdd86d675f8958d7cfabe3938b)
  * 「Arxiv 2024.05.16」A Tale of Two Languages: Large-Vocabulary Continuous Sign Language Recognition from Spoken Language Supervision. [[Paper](https://arxiv.org/pdf/2405.10266)] [![citation](https://img.shields.io/badge/dynamic/json?label=citation&query=citationCount&url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F13195df56368306dc1c1f9733cebb8dd694c94af%3Ffields%3DcitationCount)](https://www.semanticscholar.org/paper/A-Tale-of-Two-Languages%3A-Large-Vocabulary-Sign-from-Raude-PrajwalK/13195df56368306dc1c1f9733cebb8dd694c94af)
  * 「Arxiv 2024.05.20」Continuous Sign Language Recognition with Adapted Conformer via Unsupervised Pretraining. [[Paper](https://arxiv.org/pdf/2405.12018)] [![citation](https://img.shields.io/badge/dynamic/json?label=citation&query=citationCount&url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F003e5697e896e86d333a0440582fc400fde75bd8%3Ffields%3DcitationCount)](https://www.semanticscholar.org/paper/Continuous-Sign-Language-Recognition-with-Adapted-Aloysius-Geetha/003e5697e896e86d333a0440582fc400fde75bd8)
  * 「Arxiv 2024.06.26」Continuous Sign Language Recognition Using Intra-inter Gloss Attention. [[Paper](https://arxiv.org/pdf/2406.18333)] [![citation](https://img.shields.io/badge/dynamic/json?label=citation&query=citationCount&url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F55942c89abe4caf31d24c115b7b54a7b1b38c86b%3Ffields%3DcitationCount)](https://www.semanticscholar.org/paper/Continuous-Sign-Language-Recognition-Using-Gloss-Ranjbar-Taheri/55942c89abe4caf31d24c115b7b54a7b1b38c86b)
  * 「Arxiv 2024.08.14」Sign language recognition based on deep learning and low-cost handcrafted descriptors. [[Paper](https://arxiv.org/pdf/2408.07244)] [![citation](https://img.shields.io/badge/dynamic/json?label=citation&query=citationCount&url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F0df501fb89863b7c5d7433037fdaa854873b5e2a%3Ffields%3DcitationCount)](https://www.semanticscholar.org/paper/Sign-language-recognition-based-on-deep-learning-Carneiro-Salvadeo/0df501fb89863b7c5d7433037fdaa854873b5e2a)
  * 「Arxiv 2024.09.02」SCOPE: Sign Language Contextual Processing with Embedding from LLMs [[Paper](https://arxiv.org/pdf/2409.01073)] [![citation](https://img.shields.io/badge/dynamic/json?label=citation&query=citationCount&url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2Fe5fe41a7752789b92af758e2af12cc8516e2f437%3Ffields%3DcitationCount)](https://www.semanticscholar.org/paper/SCOPE%3A-Sign-Language-Contextual-Processing-with-Liu-Zhang/e5fe41a7752789b92af758e2af12cc8516e2f437)
  * 「Arxiv 2024.09.18」A Chinese Continuous Sign Language Dataset Based on Complex Environments. [[Paper](https://arxiv.org/pdf/2409.11960)] [![citation](https://img.shields.io/badge/dynamic/json?label=citation&query=citationCount&url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2Ffecd1aca44a468d7ca2993abe4d9ee1de002e9b6%3Ffields%3DcitationCount)](https://www.semanticscholar.org/paper/A-Chinese-Continuous-Sign-Language-Dataset-Based-on-Zhu-Li/fecd1aca44a468d7ca2993abe4d9ee1de002e9b6)
  * 「Arxiv 2024.11.07」Continuous Sign Language Recognition System using Deep Learning with MediaPipe Holistic. [[Paper](https://arxiv.org/pdf/2411.04517)] [![citation](https://img.shields.io/badge/dynamic/json?label=citation&query=citationCount&url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F5e022622dde9266e059d4189a5b0fc1f105f26af%3Ffields%3DcitationCount)](https://www.semanticscholar.org/paper/Continuous-Sign-Language-Recognition-System-Using-Srivastava-Singh/5e022622dde9266e059d4189a5b0fc1f105f26af)
  * 「Arxiv 2025.03.11」OLMD: Orientation-aware Long-term Motion Decoupling for Continuous Sign Language Recognition. [[Paper](https://arxiv.org/pdf/2503.08205)] [![citation](https://img.shields.io/badge/dynamic/json?label=citation&query=citationCount&url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2Ffa37313bf1a4558af1462085e70b884b1418fd50%3Ffields%3DcitationCount)](https://www.semanticscholar.org/paper/OLMD%3A-Orientation-aware-Long-term-Motion-Decoupling-Yu-Liu/fa37313bf1a4558af1462085e70b884b1418fd50)
  * 「Arxiv 2025.03.21」Stack Transformer Based Spatial-Temporal Attention Model for Dynamic Multi-Culture Sign Language Recognition [[Paper](https://arxiv.org/pdf/2503.16855)] [![citation](https://img.shields.io/badge/dynamic/json?label=citation&query=citationCount&url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2Fd686bf28db6bebb60bd7e5d09f8f10c07f812761%3Ffields%3DcitationCount)](https://www.semanticscholar.org/paper/Stack-Transformer-Based-Spatial-Temporal-Attention-Hirooka-Miah/d686bf28db6bebb60bd7e5d09f8f10c07f812761)
  * 「Arxiv 2025.04.02」CLIP-SLA: Parameter-Efficient CLIP Adaptation for Continuous Sign Language Recognition. [[Paper](https://arxiv.org/pdf/2504.01666)] [![citation](https://img.shields.io/badge/dynamic/json?label=citation&query=citationCount&url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2Fcbe183fa6ae385a4d3a16da2ce7657b31ffb206c%3Ffields%3DcitationCount)](https://www.semanticscholar.org/paper/CLIP-SLA%3A-Parameter-Efficient-CLIP-Adaptation-for-Alyami-Luqman/cbe183fa6ae385a4d3a16da2ce7657b31ffb206c)
  * 「Arxiv 2025.04.22」SignX: The Foundation Model for Sign Recognition. [[Paper](https://arxiv.org/pdf/2504.16315)] [![citation](https://img.shields.io/badge/dynamic/json?label=citation&query=citationCount&url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F815ec1668d1eeb078fa3a7d536aa78bfd42b070b%3Ffields%3DcitationCount)](https://www.semanticscholar.org/paper/SignX%3A-The-Foundation-Model-for-Sign-Recognition-Fang-Sui/815ec1668d1eeb078fa3a7d536aa78bfd42b070b)

 
